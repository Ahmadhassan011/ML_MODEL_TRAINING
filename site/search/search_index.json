{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Universal Data Indexing & Retrieval An intelligent system for managing, indexing, and retrieving diverse data sources , designed for building robust knowledge bases and RAG applications. \ud83d\ude80 Get Started GitHub Repository Core Capabilities folder_open File & Directory Indexing Effortlessly index individual files or entire directories, extracting text content and metadata. code Code Repository Analysis Ingest and analyze codebases to build intelligent repositories for code understanding and search. article Document Loading Support for various document types (PDFs, text, HTML) through `langchain_community.document_loaders`. search Advanced Retrieval Integrate with powerful search engines like Elasticsearch for efficient semantic search and RAG. manage_history Metadata Management Extract, store, and leverage rich metadata for enhanced filtering and contextual understanding. api Flexible Integrations Designed for seamless integration with LLMs and other external systems for diverse applications. Why This Project? Build Smarter RAG Systems Provide your Language Models with accurate, up-to-date, and context-rich information. Centralize Knowledge Create a unified, searchable repository from disparate data sources across your organization. Accelerate Development Spend less time on data ingestion and more time on building innovative AI applications. How to Get Started cloud_download Clone the Repository Begin by getting the project code from its GitHub repository. git clone https://github.com/your-username/your-repository.git cd your-repository build Install Dependencies Set up your environment by installing the necessary Python packages (e.g., `langchain`, `elasticsearch`). pip install -r requirements.txt play_arrow Start Indexing Utilize the provided CLI or API to start indexing your data sources. python -m cli index --path ./my_data","title":"Home"},{"location":"architecture/","text":"This page describes the architecture of the Simple ML Pipeline. Components The pipeline is composed of several Python modules, each responsible for a specific part of the workflow. graph TD; A[CLI] --> B(Main); B --> C{Data}; B --> D{Preprocessing}; B --> E{Model}; B --> F{Training}; B --> G{Evaluate}; B --> H{Predict}; cli.py : The command-line interface for running the pipeline. It parses command-line arguments and calls the main function. main.py : The main entry point of the pipeline. It orchestrates the entire workflow, from data generation to model evaluation and saving. data.py : Generates synthetic data for the linear regression model. preprocessing.py : Preprocesses the data, including splitting it into training and testing sets. model.py : Defines the simple linear regression model using PyTorch. training.py : Trains the model using the training data. evaluate.py : Evaluates the trained model on the test data. predict.py : Provides a function to make predictions on new data points using the trained model.","title":"Architecture"},{"location":"architecture/#components","text":"The pipeline is composed of several Python modules, each responsible for a specific part of the workflow. graph TD; A[CLI] --> B(Main); B --> C{Data}; B --> D{Preprocessing}; B --> E{Model}; B --> F{Training}; B --> G{Evaluate}; B --> H{Predict}; cli.py : The command-line interface for running the pipeline. It parses command-line arguments and calls the main function. main.py : The main entry point of the pipeline. It orchestrates the entire workflow, from data generation to model evaluation and saving. data.py : Generates synthetic data for the linear regression model. preprocessing.py : Preprocesses the data, including splitting it into training and testing sets. model.py : Defines the simple linear regression model using PyTorch. training.py : Trains the model using the training data. evaluate.py : Evaluates the trained model on the test data. predict.py : Provides a function to make predictions on new data points using the trained model.","title":"Components"},{"location":"cli/","text":"cli run () The command-line interface for the machine learning pipeline. Source code in cli.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def run (): \"\"\" The command-line interface for the machine learning pipeline. \"\"\" parser = argparse . ArgumentParser ( description = \"Run a simple machine learning pipeline.\" ) parser . add_argument ( \"--n_samples\" , type = int , default = 100 , help = \"Number of samples to generate.\" , ) parser . add_argument ( \"--num_epochs\" , type = int , default = 100 , help = \"Number of epochs to train for.\" , ) parser . add_argument ( \"--learning_rate\" , type = float , default = 0.01 , help = \"Learning rate for the optimizer.\" , ) args = parser . parse_args () main ( n_samples = args . n_samples , num_epochs = args . num_epochs , learning_rate = args . learning_rate , )","title":"CLI"},{"location":"cli/#cli","text":"","title":"cli"},{"location":"cli/#cli.run","text":"The command-line interface for the machine learning pipeline. Source code in cli.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def run (): \"\"\" The command-line interface for the machine learning pipeline. \"\"\" parser = argparse . ArgumentParser ( description = \"Run a simple machine learning pipeline.\" ) parser . add_argument ( \"--n_samples\" , type = int , default = 100 , help = \"Number of samples to generate.\" , ) parser . add_argument ( \"--num_epochs\" , type = int , default = 100 , help = \"Number of epochs to train for.\" , ) parser . add_argument ( \"--learning_rate\" , type = float , default = 0.01 , help = \"Learning rate for the optimizer.\" , ) args = parser . parse_args () main ( n_samples = args . n_samples , num_epochs = args . num_epochs , learning_rate = args . learning_rate , )","title":"run"},{"location":"data-flow/","text":"This page describes the data flow within the Simple ML Pipeline. Data Flow Diagram The following diagram illustrates how data flows through the different components of the pipeline. sequenceDiagram participant User participant CLI participant Main participant Data participant Preprocessing participant Model participant Training participant Evaluate participant Predict User->>CLI: Run pipeline with parameters CLI->>Main: Call main function with arguments Main->>Data: Get synthetic data Data-->>Main: Return X and y Main->>Preprocessing: Split data into train/test sets Preprocessing-->>Main: Return X_train, y_train, X_test, y_test Main->>Model: Initialize SimpleRegressionModel Model-->>Main: Return model Main->>Training: Train model Training-->>Main: Return trained model Main->>Evaluate: Evaluate model Evaluate-->>Main: Print evaluation results Main->>Predict: (Optional) Make predictions Predict-->>Main: Return prediction","title":"Data Flow"},{"location":"data-flow/#data-flow-diagram","text":"The following diagram illustrates how data flows through the different components of the pipeline. sequenceDiagram participant User participant CLI participant Main participant Data participant Preprocessing participant Model participant Training participant Evaluate participant Predict User->>CLI: Run pipeline with parameters CLI->>Main: Call main function with arguments Main->>Data: Get synthetic data Data-->>Main: Return X and y Main->>Preprocessing: Split data into train/test sets Preprocessing-->>Main: Return X_train, y_train, X_test, y_test Main->>Model: Initialize SimpleRegressionModel Model-->>Main: Return model Main->>Training: Train model Training-->>Main: Return trained model Main->>Evaluate: Evaluate model Evaluate-->>Main: Print evaluation results Main->>Predict: (Optional) Make predictions Predict-->>Main: Return prediction","title":"Data Flow Diagram"},{"location":"data/","text":"data get_data ( n_samples = 100 ) Generates synthetic data for a simple linear regression model. Parameters: Name Type Description Default n_samples int The number of samples to generate. 100 Returns: Name Type Description tuple A tuple containing the features (X) and the target (y). Source code in data.py 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_data ( n_samples = 100 ): \"\"\" Generates synthetic data for a simple linear regression model. Args: n_samples (int): The number of samples to generate. Returns: tuple: A tuple containing the features (X) and the target (y). \"\"\" X = np . random . rand ( n_samples , 1 ) * 10 y = 2 * X + 1 + np . random . randn ( n_samples , 1 ) * 2 return X , y","title":"Data"},{"location":"data/#data","text":"","title":"data"},{"location":"data/#data.get_data","text":"Generates synthetic data for a simple linear regression model. Parameters: Name Type Description Default n_samples int The number of samples to generate. 100 Returns: Name Type Description tuple A tuple containing the features (X) and the target (y). Source code in data.py 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_data ( n_samples = 100 ): \"\"\" Generates synthetic data for a simple linear regression model. Args: n_samples (int): The number of samples to generate. Returns: tuple: A tuple containing the features (X) and the target (y). \"\"\" X = np . random . rand ( n_samples , 1 ) * 10 y = 2 * X + 1 + np . random . randn ( n_samples , 1 ) * 2 return X , y","title":"get_data"},{"location":"evaluate/","text":"evaluate evaluate_model ( model , X_test , y_test ) Evaluates the trained simple regression model. Parameters: Name Type Description Default model Module The trained model. required X_test Tensor The testing features. required y_test Tensor The testing target. required Source code in evaluate.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def evaluate_model ( model , X_test , y_test ): \"\"\" Evaluates the trained simple regression model. Args: model (torch.nn.Module): The trained model. X_test (torch.Tensor): The testing features. y_test (torch.Tensor): The testing target. \"\"\" model . eval () with torch . no_grad (): predicted = model ( X_test ) criterion = nn . MSELoss () loss = criterion ( predicted , y_test ) print ( f \"Mean Squared Error on test data: { loss . item () : .4f } \" )","title":"Evaluate"},{"location":"evaluate/#evaluate","text":"","title":"evaluate"},{"location":"evaluate/#evaluate.evaluate_model","text":"Evaluates the trained simple regression model. Parameters: Name Type Description Default model Module The trained model. required X_test Tensor The testing features. required y_test Tensor The testing target. required Source code in evaluate.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def evaluate_model ( model , X_test , y_test ): \"\"\" Evaluates the trained simple regression model. Args: model (torch.nn.Module): The trained model. X_test (torch.Tensor): The testing features. y_test (torch.Tensor): The testing target. \"\"\" model . eval () with torch . no_grad (): predicted = model ( X_test ) criterion = nn . MSELoss () loss = criterion ( predicted , y_test ) print ( f \"Mean Squared Error on test data: { loss . item () : .4f } \" )","title":"evaluate_model"},{"location":"main/","text":"main main ( n_samples = 100 , num_epochs = 100 , learning_rate = 0.01 ) The main function to run the machine learning pipeline. Source code in main.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def main ( n_samples = 100 , num_epochs = 100 , learning_rate = 0.01 ): \"\"\" The main function to run the machine learning pipeline. \"\"\" # Get data X , y = get_data ( n_samples ) # Preprocess data X_train , y_train , X_test , y_test = preprocess_data ( X , y ) # Initialize model input_dim = 1 output_dim = 1 model = SimpleRegressionModel ( input_dim , output_dim ) # Train model trained_model = train_model ( model , X_train , y_train , num_epochs , learning_rate ) # Evaluate model evaluate_model ( trained_model , X_test , y_test ) # Save the model torch . save ( trained_model . state_dict (), \"model.pth\" ) print ( \"Model saved to model.pth\" )","title":"Main"},{"location":"main/#main","text":"","title":"main"},{"location":"main/#main.main","text":"The main function to run the machine learning pipeline. Source code in main.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def main ( n_samples = 100 , num_epochs = 100 , learning_rate = 0.01 ): \"\"\" The main function to run the machine learning pipeline. \"\"\" # Get data X , y = get_data ( n_samples ) # Preprocess data X_train , y_train , X_test , y_test = preprocess_data ( X , y ) # Initialize model input_dim = 1 output_dim = 1 model = SimpleRegressionModel ( input_dim , output_dim ) # Train model trained_model = train_model ( model , X_train , y_train , num_epochs , learning_rate ) # Evaluate model evaluate_model ( trained_model , X_test , y_test ) # Save the model torch . save ( trained_model . state_dict (), \"model.pth\" ) print ( \"Model saved to model.pth\" )","title":"main"},{"location":"model/","text":"model SimpleRegressionModel Bases: Module A simple linear regression model. Source code in model.py 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class SimpleRegressionModel ( nn . Module ): \"\"\" A simple linear regression model. \"\"\" def __init__ ( self , input_dim , output_dim ): \"\"\" Initializes the SimpleRegressionModel. Args: input_dim (int): The dimension of the input. output_dim (int): The dimension of the output. \"\"\" super ( SimpleRegressionModel , self ) . __init__ () self . linear = nn . Linear ( input_dim , output_dim ) def forward ( self , x ): \"\"\" The forward pass of the model. Args: x (torch.Tensor): The input tensor. Returns: torch.Tensor: The output of the model. \"\"\" return self . linear ( x ) __init__ ( input_dim , output_dim ) Initializes the SimpleRegressionModel. Parameters: Name Type Description Default input_dim int The dimension of the input. required output_dim int The dimension of the output. required Source code in model.py 7 8 9 10 11 12 13 14 15 16 def __init__ ( self , input_dim , output_dim ): \"\"\" Initializes the SimpleRegressionModel. Args: input_dim (int): The dimension of the input. output_dim (int): The dimension of the output. \"\"\" super ( SimpleRegressionModel , self ) . __init__ () self . linear = nn . Linear ( input_dim , output_dim ) forward ( x ) The forward pass of the model. Parameters: Name Type Description Default x Tensor The input tensor. required Returns: Type Description torch.Tensor: The output of the model. Source code in model.py 18 19 20 21 22 23 24 25 26 27 28 def forward ( self , x ): \"\"\" The forward pass of the model. Args: x (torch.Tensor): The input tensor. Returns: torch.Tensor: The output of the model. \"\"\" return self . linear ( x )","title":"Model"},{"location":"model/#model","text":"","title":"model"},{"location":"model/#model.SimpleRegressionModel","text":"Bases: Module A simple linear regression model. Source code in model.py 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class SimpleRegressionModel ( nn . Module ): \"\"\" A simple linear regression model. \"\"\" def __init__ ( self , input_dim , output_dim ): \"\"\" Initializes the SimpleRegressionModel. Args: input_dim (int): The dimension of the input. output_dim (int): The dimension of the output. \"\"\" super ( SimpleRegressionModel , self ) . __init__ () self . linear = nn . Linear ( input_dim , output_dim ) def forward ( self , x ): \"\"\" The forward pass of the model. Args: x (torch.Tensor): The input tensor. Returns: torch.Tensor: The output of the model. \"\"\" return self . linear ( x )","title":"SimpleRegressionModel"},{"location":"model/#model.SimpleRegressionModel.__init__","text":"Initializes the SimpleRegressionModel. Parameters: Name Type Description Default input_dim int The dimension of the input. required output_dim int The dimension of the output. required Source code in model.py 7 8 9 10 11 12 13 14 15 16 def __init__ ( self , input_dim , output_dim ): \"\"\" Initializes the SimpleRegressionModel. Args: input_dim (int): The dimension of the input. output_dim (int): The dimension of the output. \"\"\" super ( SimpleRegressionModel , self ) . __init__ () self . linear = nn . Linear ( input_dim , output_dim )","title":"__init__"},{"location":"model/#model.SimpleRegressionModel.forward","text":"The forward pass of the model. Parameters: Name Type Description Default x Tensor The input tensor. required Returns: Type Description torch.Tensor: The output of the model. Source code in model.py 18 19 20 21 22 23 24 25 26 27 28 def forward ( self , x ): \"\"\" The forward pass of the model. Args: x (torch.Tensor): The input tensor. Returns: torch.Tensor: The output of the model. \"\"\" return self . linear ( x )","title":"forward"},{"location":"predict/","text":"predict main () Loads the model and makes a prediction on a sample data point. Source code in predict.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def main (): \"\"\" Loads the model and makes a prediction on a sample data point. \"\"\" # Load the trained model input_dim = 1 output_dim = 1 model = SimpleRegressionModel ( input_dim , output_dim ) model . load_state_dict ( torch . load ( \"model.pth\" )) # Create a new data point new_data = np . array ([ 5.0 ]) # Make a prediction prediction = predict ( model , new_data ) print ( f \"Prediction for input { new_data [ 0 ] } : { prediction : .4f } \" ) predict ( model , data_point ) Makes a prediction on a new data point. Parameters: Name Type Description Default model Module The trained model. required data_point ndarray The new data point. required Returns: Name Type Description float The prediction. Source code in predict.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def predict ( model , data_point ): \"\"\" Makes a prediction on a new data point. Args: model (torch.nn.Module): The trained model. data_point (np.ndarray): The new data point. Returns: float: The prediction. \"\"\" model . eval () with torch . no_grad (): data_tensor = torch . from_numpy ( data_point . astype ( np . float32 )) data_tensor = data_tensor . unsqueeze ( 0 ) # Add batch dimension prediction = model ( data_tensor ) return prediction . item ()","title":"Predict"},{"location":"predict/#predict","text":"","title":"predict"},{"location":"predict/#predict.main","text":"Loads the model and makes a prediction on a sample data point. Source code in predict.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def main (): \"\"\" Loads the model and makes a prediction on a sample data point. \"\"\" # Load the trained model input_dim = 1 output_dim = 1 model = SimpleRegressionModel ( input_dim , output_dim ) model . load_state_dict ( torch . load ( \"model.pth\" )) # Create a new data point new_data = np . array ([ 5.0 ]) # Make a prediction prediction = predict ( model , new_data ) print ( f \"Prediction for input { new_data [ 0 ] } : { prediction : .4f } \" )","title":"main"},{"location":"predict/#predict.predict","text":"Makes a prediction on a new data point. Parameters: Name Type Description Default model Module The trained model. required data_point ndarray The new data point. required Returns: Name Type Description float The prediction. Source code in predict.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def predict ( model , data_point ): \"\"\" Makes a prediction on a new data point. Args: model (torch.nn.Module): The trained model. data_point (np.ndarray): The new data point. Returns: float: The prediction. \"\"\" model . eval () with torch . no_grad (): data_tensor = torch . from_numpy ( data_point . astype ( np . float32 )) data_tensor = data_tensor . unsqueeze ( 0 ) # Add batch dimension prediction = model ( data_tensor ) return prediction . item ()","title":"predict"},{"location":"preprocessing/","text":"preprocessing preprocess_data ( X , y ) Preprocesses the data by splitting it into training and testing sets and converting it to PyTorch tensors. Parameters: Name Type Description Default X ndarray The features. required y ndarray The target. required Returns: Name Type Description tuple A tuple containing the training and testing data as PyTorch tensors. Source code in preprocessing.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def preprocess_data ( X , y ): \"\"\" Preprocesses the data by splitting it into training and testing sets and converting it to PyTorch tensors. Args: X (np.ndarray): The features. y (np.ndarray): The target. Returns: tuple: A tuple containing the training and testing data as PyTorch tensors. \"\"\" X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 42 ) X_train_tensor = torch . from_numpy ( X_train . astype ( np . float32 )) y_train_tensor = torch . from_numpy ( y_train . astype ( np . float32 )) X_test_tensor = torch . from_numpy ( X_test . astype ( np . float32 )) y_test_tensor = torch . from_numpy ( y_test . astype ( np . float32 )) return X_train_tensor , y_train_tensor , X_test_tensor , y_test_tensor","title":"Preprocessing"},{"location":"preprocessing/#preprocessing","text":"","title":"preprocessing"},{"location":"preprocessing/#preprocessing.preprocess_data","text":"Preprocesses the data by splitting it into training and testing sets and converting it to PyTorch tensors. Parameters: Name Type Description Default X ndarray The features. required y ndarray The target. required Returns: Name Type Description tuple A tuple containing the training and testing data as PyTorch tensors. Source code in preprocessing.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def preprocess_data ( X , y ): \"\"\" Preprocesses the data by splitting it into training and testing sets and converting it to PyTorch tensors. Args: X (np.ndarray): The features. y (np.ndarray): The target. Returns: tuple: A tuple containing the training and testing data as PyTorch tensors. \"\"\" X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.2 , random_state = 42 ) X_train_tensor = torch . from_numpy ( X_train . astype ( np . float32 )) y_train_tensor = torch . from_numpy ( y_train . astype ( np . float32 )) X_test_tensor = torch . from_numpy ( X_test . astype ( np . float32 )) y_test_tensor = torch . from_numpy ( y_test . astype ( np . float32 )) return X_train_tensor , y_train_tensor , X_test_tensor , y_test_tensor","title":"preprocess_data"},{"location":"training/","text":"training train_model ( model , X_train , y_train , num_epochs = 100 , learning_rate = 0.01 ) Trains the simple regression model. Parameters: Name Type Description Default model Module The model to train. required X_train Tensor The training features. required y_train Tensor The training target. required num_epochs int The number of epochs to train for. 100 learning_rate float The learning rate for the optimizer. 0.01 Returns: Type Description torch.nn.Module: The trained model. Source code in training.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def train_model ( model , X_train , y_train , num_epochs = 100 , learning_rate = 0.01 ): \"\"\" Trains the simple regression model. Args: model (torch.nn.Module): The model to train. X_train (torch.Tensor): The training features. y_train (torch.Tensor): The training target. num_epochs (int): The number of epochs to train for. learning_rate (float): The learning rate for the optimizer. Returns: torch.nn.Module: The trained model. \"\"\" criterion = nn . MSELoss () optimizer = optim . SGD ( model . parameters (), lr = learning_rate ) for epoch in range ( num_epochs ): model . train () # Forward pass outputs = model ( X_train ) loss = criterion ( outputs , y_train ) # Backward and optimize optimizer . zero_grad () loss . backward () optimizer . step () if ( epoch + 1 ) % 10 == 0 : print ( f \"Epoch [ { epoch + 1 } / { num_epochs } ], Loss: { loss . item () : .4f } \" ) return model","title":"Training"},{"location":"training/#training","text":"","title":"training"},{"location":"training/#training.train_model","text":"Trains the simple regression model. Parameters: Name Type Description Default model Module The model to train. required X_train Tensor The training features. required y_train Tensor The training target. required num_epochs int The number of epochs to train for. 100 learning_rate float The learning rate for the optimizer. 0.01 Returns: Type Description torch.nn.Module: The trained model. Source code in training.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 def train_model ( model , X_train , y_train , num_epochs = 100 , learning_rate = 0.01 ): \"\"\" Trains the simple regression model. Args: model (torch.nn.Module): The model to train. X_train (torch.Tensor): The training features. y_train (torch.Tensor): The training target. num_epochs (int): The number of epochs to train for. learning_rate (float): The learning rate for the optimizer. Returns: torch.nn.Module: The trained model. \"\"\" criterion = nn . MSELoss () optimizer = optim . SGD ( model . parameters (), lr = learning_rate ) for epoch in range ( num_epochs ): model . train () # Forward pass outputs = model ( X_train ) loss = criterion ( outputs , y_train ) # Backward and optimize optimizer . zero_grad () loss . backward () optimizer . step () if ( epoch + 1 ) % 10 == 0 : print ( f \"Epoch [ { epoch + 1 } / { num_epochs } ], Loss: { loss . item () : .4f } \" ) return model","title":"train_model"}]}